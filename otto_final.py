import json
from collections import defaultdict
import pandas as pd

# æ˜¯å¦ä½¿ç”¨ sampleï¼ˆTrueï¼šè°ƒè¯•æ¨¡å¼ï¼Œä»…åŠ è½½å‰ 100000 æ¡ï¼›Falseï¼šåŠ è½½å…¨éƒ¨æ•°æ®ï¼‰
USE_SAMPLE = True
SAMPLE_SIZE = 100000

train_sessions = []
test_sessions = []
aid_set = set()

if USE_SAMPLE:
    print(f"ä½¿ç”¨ sample æ¨¡å¼ï¼Œä»…åŠ è½½å‰ {SAMPLE_SIZE} æ¡è®­ç»ƒæ•°æ®")
    chunks = pd.read_json(r'X:/otto-recommender-system/train.jsonl', lines=True, chunksize=SAMPLE_SIZE)
    for chunk in chunks:
        for _, row in chunk.iterrows():
            session_id = row['session']
            events = row['events']
            events.sort(key=lambda x: x['ts'])
            aids = [e['aid'] for e in events]
            types = [e['type'] for e in events]
            train_sessions.append((session_id, aids, types))
            aid_set.update(aids)
        break  #  åªåŠ è½½ç¬¬ä¸€ä¸ª chunk
else:
    print("ä½¿ç”¨å…¨é‡è®­ç»ƒæ•°æ®")
    with open(r'X:/otto-recommender-system/train.jsonl', 'r', encoding='utf-8') as f:
        for line in f:
            data = json.loads(line.strip())
            session_id = data['session']
            events = data['events']
            events.sort(key=lambda x: x['ts'])
            aids = [e['aid'] for e in events]
            types = [e['type'] for e in events]
            train_sessions.append((session_id, aids, types))
            aid_set.update(aids)

# æ— è®ºæ˜¯å¦ sampleï¼Œæµ‹è¯•é›†éƒ½åŠ è½½å…¨é‡
with open(r'X:/otto-recommender-system/test.jsonl', 'r', encoding='utf-8') as f:
    for line in f:
        data = json.loads(line.strip())
        session_id = data['session']
        events = data['events']
        events.sort(key=lambda x: x['ts'])
        aids = [e['aid'] for e in events]
        types = [e['type'] for e in events]
        test_sessions.append((session_id, aids, types))
        aid_set.update(aids)

# æ„å»ºå•†å“IDç´¢å¼•æ˜ å°„
aid_list = sorted(list(aid_set))
aid2idx = {aid: idx+1 for idx, aid in enumerate(aid_list)}
idx2aid = {idx+1: aid for idx, aid in enumerate(aid_list)}
num_items = len(aid_list) + 1


# å°†è¡Œä¸ºç±»å‹è½¬æ¢ä¸ºç´¢å¼•
type2idx = {'clicks': 0, 'carts': 1, 'orders': 2}

# æ„å»ºè®­ç»ƒæ ·æœ¬åˆ—è¡¨
train_data = []
for (session_id, aids, types) in train_sessions:
    # è½¬ä¸ºç´¢å¼•è¡¨ç¤º
    seq = [aid2idx[a] for a in aids]
    t_seq = [type2idx[t] for t in types]
    # æ¯ä¸ªä½ç½® iï¼ˆä»1åˆ°len-1ï¼‰äº§ç”Ÿä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼šå‰ç¼€ seq[0:i] -> ä¸‹ä¸€ä¸ª item seq[i], åŠäº‹ä»¶ç±»å‹ t_seq[i]
    for i in range(1, len(seq)):
        prefix = seq[:i]
        target_aid = seq[i]        # ä¸‹ä¸€æ­¥å•†å“ç´¢å¼•ï¼ˆæ­£æ ·æœ¬ï¼‰
        target_type = t_seq[i]     # äº‹ä»¶ç±»å‹ä»»åŠ¡ç´¢å¼•
        train_data.append((prefix, target_aid, target_type))
# ç®€å•æ‰“ä¹±ï¼ˆå¯é€‰ï¼‰
import random
random.shuffle(train_data)

import torch
import torch.nn as nn
import torch.nn.functional as F

class SASRec(nn.Module):
    def __init__(self, num_items, embed_dim=64, num_heads=2, num_layers=2, dropout=0.2):
        super(SASRec, self).__init__()
        self.embed_dim = embed_dim
        # å•†å“åµŒå…¥å’Œä½ç½®åµŒå…¥
        self.item_embedding = nn.Embedding(num_items, embed_dim, padding_idx=0)
        self.pos_embedding = nn.Embedding(1000, embed_dim)  # å‡è®¾æœ€å¤§åºåˆ—é•¿åº¦ä¸è¶…è¿‡1000
        # Transformer Encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, nhead=num_heads, dropout=dropout, batch_first=True)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        # å¤šä»»åŠ¡å¤´ï¼šç‚¹å‡»/åŠ è´­/ä¸‹å•çš„ gating å‘é‡
        self.g_click = nn.Parameter(torch.ones(embed_dim))
        self.g_cart = nn.Parameter(torch.ones(embed_dim))
        self.g_order = nn.Parameter(torch.ones(embed_dim))
        self.dropout = nn.Dropout(dropout)

    def forward(self, seq, key_padding_mask=None):
        """
        seq: tensor of shape (batch, seq_len), åŒ…å«å•†å“ç´¢å¼•ï¼ˆå¡«å……ä½ç½®ä¸º0ï¼‰
        key_padding_mask: (batch, seq_len) bool tensor, True è¡¨ç¤ºè¯¥ä½ç½®æ˜¯å¡«å……éœ€å±è”½
        è¿”å›ï¼šæœ€åä¸€ä¸ªä½ç½®çš„ä¸Šä¸‹æ–‡å‘é‡ (batch, embed_dim)
        """
        # å•†å“åµŒå…¥ + ä½ç½®åµŒå…¥
        emb = self.item_embedding(seq)  # (batch, seq_len, embed_dim)
        positions = torch.arange(seq.size(1), device=seq.device).unsqueeze(0)
        pos_emb = self.pos_embedding(positions)
        h = emb + pos_emb
        h = self.dropout(h)
        # Transformer ç¼–ç ï¼ˆä½¿ç”¨ key_padding_mask å±è”½å¡«å……ä½ç½®ï¼‰
        h = self.transformer(h, src_key_padding_mask=key_padding_mask)
        # å–æ¯åºåˆ—æœ€åä¸€ä¸ªæœ‰æ•ˆä½ç½®çš„è¾“å‡ºä½œä¸ºä¸Šä¸‹æ–‡
        # lengths = total length excluding padding = ~
        # ç”±äº Transformer ä¸è‡ªåŠ¨å¿½ç•¥å¡«å……ï¼Œæˆ‘ä»¬ä» key_padding_mask å¾—çŸ¥å®é™…é•¿åº¦
        # å–æœ€åä¸€ä¸ªéå¡«å……ä½ç½®
        batch_size, seq_len, _ = h.size()
        last_h = []
        if key_padding_mask is not None:
            for i in range(batch_size):
                # æ‰¾å‡ºç¬¬ i ä¸ªåºåˆ—æœ‰å¤šå°‘ä¸ªå®é™…æ¡ç›®
                valid_len = (key_padding_mask[i] == 0).sum().item()
                # å–æœ€åä¸€ä¸ªéå¡«å……ä½ç½®çš„è¾“å‡º
                if valid_len > 0:
                    last_h.append(h[i, valid_len-1, :])
                else:
                    # æç«¯æƒ…å†µï¼šå…¨å¡«å……ï¼Œå–å…¨é›¶å‘é‡
                    last_h.append(torch.zeros(self.embed_dim, device=h.device))
            last_h = torch.stack(last_h, dim=0)  # (batch, embed_dim)
        else:
            # å¦‚æœæ— å¡«å……ï¼ˆbatchå†…ç­‰é•¿ï¼‰ï¼Œåˆ™ç›´æ¥å–æœ€åä¸€åˆ—
            last_h = h[:, -1, :]  # (batch, embed_dim)
        return last_h  # (batch, embed_dim)

import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# è‡ªå®šä¹‰ Dataset
class OttoDataset(Dataset):
    def __init__(self, data_list):
        self.data = data_list  # list of (prefix_seq, target_aid, target_type)
    def __len__(self):
        return len(self.data)
    def __getitem__(self, idx):
        prefix, aid, ttype = self.data[idx]
        return prefix, aid, ttype

# ç”Ÿæˆ DataLoader æ—¶éœ€è¦ Pad å¡«å……
def collate_batch(batch):
    sequences, pos_items, types = zip(*batch)
    lengths = [len(seq) for seq in sequences]
    max_len = max(lengths)
    padded_seqs = []
    key_padding_mask = []
    for seq in sequences:
        pad_len = max_len - len(seq)
        padded_seqs.append(seq + [0]*pad_len)  # å¡«å……0
        key_padding_mask.append([0]*len(seq) + [1]*pad_len)  # 1 è¡¨ç¤ºå¡«å……ä½ç½®
    return (torch.LongTensor(padded_seqs),
            torch.BoolTensor(key_padding_mask),
            torch.LongTensor(pos_items),
            torch.LongTensor(types))

# åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†ï¼ˆä¾‹å¦‚80%è®­ç»ƒï¼Œ20%éªŒè¯ï¼‰
random.shuffle(train_data)
split = int(0.8 * len(train_data))
train_list = train_data[:split]
val_list = train_data[split:]

train_loader = DataLoader(OttoDataset(train_list), batch_size=32,
                          shuffle=True, collate_fn=collate_batch)
val_loader   = DataLoader(OttoDataset(val_list), batch_size=32,
                          shuffle=False, collate_fn=collate_batch)

# åˆå§‹åŒ–æ¨¡å‹ä¸ä¼˜åŒ–å™¨
model = SASRec(num_items=num_items, embed_dim=64, num_heads=4, num_layers=2, dropout=0.1)
model = model.cuda()
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.BCEWithLogitsLoss()

# è´Ÿæ ·æœ¬æ•°é‡
n_neg = 10

# è®­ç»ƒå¾ªç¯ï¼ˆç®€åŒ–ï¼ŒæœªåŒ…æ‹¬æ—©åœç­‰ç»†èŠ‚ï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

import time
import datetime

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

for epoch in range(5):
    print(f"\n--- Epoch {epoch+1}/5 å¼€å§‹ ---")
    start_time = time.time()

    model.train()
    total_loss = 0.0
    batch_count = len(train_loader)

    for batch_idx, batch in enumerate(train_loader):
        seqs, padding_mask, pos_items, types = batch
        seqs = seqs.to(device)
        padding_mask = padding_mask.to(device)
        pos_items = pos_items.to(device)
        types = types.to(device)

        optimizer.zero_grad()
        context = model(seqs, key_padding_mask=padding_mask)

        batch_size = context.size(0)
        embed_dim = context.size(1)

        g_vectors = torch.stack([model.g_click, model.g_cart, model.g_order])[types]
        h_t = context * g_vectors
        pos_emb = model.item_embedding(pos_items)
        logit_pos = torch.sum(h_t * pos_emb, dim=1)
        loss_pos = F.softplus(-logit_pos)

        neg_ids = torch.randint(1, num_items, (batch_size, n_neg), device=device)
        neg_embs = model.item_embedding(neg_ids)
        h_t_expand = h_t.unsqueeze(1)
        logits_neg = torch.sum(h_t_expand * neg_embs, dim=2)
        loss_neg = F.softplus(logits_neg).sum(dim=1)

        loss = loss_pos + loss_neg
        batch_loss = loss.mean()
        batch_loss.backward()
        optimizer.step()

        total_loss += batch_loss.item()

        # ğŸŸ¡ æ—¥å¿—ï¼šæ¯ 100 ä¸ª batch è¾“å‡ºä¸€æ¬¡
        if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == batch_count:
            elapsed = time.time() - start_time
            print(f"[{datetime.datetime.now().strftime('%H:%M:%S')}] "
                  f"Epoch {epoch+1} | Batch {batch_idx+1}/{batch_count} | "
                  f"AvgLoss: {total_loss/(batch_idx+1):.4f} | Time Elapsed: {elapsed:.1f}s")

    print(f"âœ… Epoch {epoch+1} ç»“æŸï¼Œæ€»è®­ç»ƒæŸå¤±ï¼š{total_loss:.4f}ï¼Œè€—æ—¶ï¼š{(time.time() - start_time):.1f}s")
    
    
    # --- éªŒè¯é˜¶æ®µï¼ˆç®€åŒ–ç¤ºæ„ï¼‰ ---
    model.eval()
    all_labels = {0: [], 1: [], 2: []}
    all_scores = {0: [], 1: [], 2: []}
    hit_count = {0: 0, 1: 0, 2: 0}
    total_count = {0: 0, 1: 0, 2: 0}
    with torch.no_grad():
        for batch in val_loader:
            seqs, padding_mask, pos_items, types = batch
            seqs, padding_mask, pos_items, types = seqs.cuda(), padding_mask.cuda(), pos_items.cuda(), types.cuda()
            context = model(seqs, key_padding_mask=padding_mask)
            for i in range(context.size(0)):
                h = context[i]; t = types[i].item(); pos = pos_items[i].item()
                total_count[t] += 1
                # è®¡ç®—è¯¥æ ·æœ¬å¯¹åº”ä»»åŠ¡çš„åˆ†æ•°ï¼ˆå¯¹æ­£è´Ÿæ ·æœ¬åˆ†åˆ«è®°å½•ï¼‰
                if t == 0: g = model.g_click
                elif t == 1: g = model.g_cart
                else: g = model.g_order
                h_t = h * g
                score_pos = torch.dot(h_t, model.item_embedding.weight[pos]).item()
                all_scores[t].append(score_pos)
                all_labels[t].append(1)  # æ­£æ ·æœ¬æ ‡è®°1
                # éšæœºé€‰å‡ ä¸ªè´Ÿæ ·æœ¬è¿›è¡Œ AUC è¯„ä¼°
                neg_ids = torch.randint(1, num_items, (n_neg,), device=h.device)
                for neg in neg_ids:
                    score_neg = torch.dot(h_t, model.item_embedding.weight[neg]).item()
                    all_scores[t].append(score_neg)
                    all_labels[t].append(0)
                # è®¡ç®— Hit Rate@20ï¼šåœ¨è¿™é‡Œç®€åŒ–ä¸ºæ£€æŸ¥æ­£æ ·æœ¬æ˜¯å¦åœ¨ top-20ï¼ˆæ­¤å¤„ä»…ç¤ºæ„ï¼‰
                # å®é™…åº”ç”¨ä¸­å¯å¯¹æ‰€æœ‰å•†å“è¯„åˆ†å¹¶å–topKï¼Œæ­¤å¤„ä¸é€ä¸€å®ç°ã€‚
                # å‡è®¾æœ‰ä¸€ä¸ªå‡½æ•° check_hit(top20_list, pos) åˆ¤æ–­å‘½ä¸­ã€‚è¿™é‡Œç•¥å†™ï¼š
                # top20_list = ... 
                # if pos in top20_list: hit_count[t] += 1
                # ...
        # è®¡ç®—å„ä»»åŠ¡ AUCï¼ˆä½¿ç”¨ sklearn æˆ–å…¶ä»–åº“ï¼›æ­¤å¤„ä¸å±•å¼€å…·ä½“å®ç°ï¼‰
        from sklearn.metrics import roc_auc_score
        aucs = {}
        for t in [0,1,2]:
            if any(all_labels[t]):
                auc = roc_auc_score(all_labels[t], all_scores[t])
            else:
                auc = float('nan')
            aucs[t] = auc
        # --- è®¡ç®— Hit Rate@20 ---
    # è·å–æ‰€æœ‰å•†å“çš„åµŒå…¥ï¼ˆæ’é™¤ padding_idx=0ï¼‰
        item_embs = model.item_embedding.weight  # (num_items, embed_dim)

        for i in range(context.size(0)):
           h = context[i]             # å½“å‰æ ·æœ¬ä¸Šä¸‹æ–‡å‘é‡
           t = types[i].item()        # å½“å‰æ ·æœ¬çš„è¡Œä¸ºç±»å‹
           pos = pos_items[i].item()  # æ­£æ ·æœ¬ aid ç´¢å¼•

           total_count[t] += 1
           if t == 0: g = model.g_click
           elif t == 1: g = model.g_cart
           else: g = model.g_order
           h_t = h * g  # åŠ æƒä¸Šä¸‹æ–‡å‘é‡

    # ä¸æ‰€æœ‰å•†å“è®¡ç®—æ‰“åˆ†
           scores = torch.matmul(item_embs, h_t)  # (num_items,)

    # æ’é™¤ paddingï¼ˆç´¢å¼•ä¸º0ï¼‰
           scores[0] = -float('inf')

    # å– top-20 ç‰©å“ç´¢å¼•
           topk = torch.topk(scores, 20).indices.tolist()

           if pos in topk:
               hit_count[t] += 1

        print(f"Val AUC: click={aucs[0]:.4f}, cart={aucs[1]:.4f}, order={aucs[2]:.4f}")
        print(f"ğŸ¯ Val HitRate@20: click={hit_rate[0]:.4f}, cart={hit_rate[1]:.4f}, order={hit_rate[2]:.4f}")

import pandas as pd

model.eval()
submission_rows = []
with torch.no_grad():
    # åˆ†æ‰¹å¤„ç†æµ‹è¯•ä¼šè¯ä»¥åŠ é€Ÿï¼ˆåŒæ ·è¦å¡«å……åºåˆ—ï¼‰
    test_loader = DataLoader(OttoDataset([(None, aids, types) for (sid, aids, types) in test_sessions]),
                             batch_size=32, collate_fn=collate_batch)
    idx = 0
    for batch in test_loader:
        seqs, padding_mask, _, _ = batch  # æµ‹è¯•é›†æ— æ­£è´Ÿæ ‡ç­¾ï¼Œè¿™é‡Œ pos_items å’Œ types éƒ½å¯ç½®ä¸º 0 å ä½
        seqs, padding_mask = seqs.cuda(), padding_mask.cuda()
        context = model(seqs, key_padding_mask=padding_mask)  # (batch, embed_dim)
        batch_size = context.size(0)
        for i in range(batch_size):
            sid, aids, types_seq = test_sessions[idx]
            idx += 1
            h = context[i]  # ä¸Šä¸‹æ–‡å‘é‡
            # å¯¹æ¯ç§è¡Œä¸ºç±»å‹åˆ†åˆ«è®¡ç®—åˆ†æ•°å¹¶é€‰ top20
            recs = {}
            for t, type_name, g in [(0, 'clicks', model.g_click),
                                     (1, 'carts', model.g_cart),
                                     (2, 'orders', model.g_order)]:
                h_t = h * g
                # è®¡ç®—æ‰€æœ‰å•†å“çš„åˆ†æ•°ï¼ˆæ­¤å¤„ç®€åŒ–ï¼Œå®é™…å¯ä¼˜åŒ–ï¼‰
                scores = torch.matmul(model.item_embedding.weight, h_t)  # (num_items,)
                # æ’é™¤ç´¢å¼•0å’Œå½“å‰ä¼šè¯å·²æœ‰çš„å•†å“
                scores[0] = -1e9
                seen = set(aids)
                for aid in seen:
                    if aid in aid2idx:
                        scores[aid2idx[aid]] = -1e9
                topk = torch.topk(scores, 20).indices.cpu().tolist()
                rec_items = [idx2aid[idx] for idx in topk]
                recs[type_name] = rec_items
            # æ·»åŠ åˆ°æäº¤è¡Œ
            session_str = str(sid)
            for t in ['clicks', 'carts', 'orders']:
                session_type = session_str + "_" + t
                pred_str = " ".join(str(x) for x in recs[t])
                submission_rows.append((session_type, pred_str))

# ä¿å­˜ä¸º CSV
sub_df = pd.DataFrame(submission_rows, columns=['session_type', 'prediction'])
sub_df.to_csv('submission.csv', index=False)

